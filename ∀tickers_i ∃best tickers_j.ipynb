{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz2wfiO1lPkq",
        "outputId": "b10be85b-d649-4eed-ba72-4ada39d802c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting correlation analysis...\n",
            "Loaded 418 tickers for analysis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing tickers:  98%|█████████▊| 408/418 [01:10<00:01,  6.06it/s]ERROR:yfinance:$WRK: possibly delisted; no timezone found\n",
            "Analyzing tickers: 100%|██████████| 418/418 [01:12<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 Composite Ranking:\n",
            "    ticker  composite_score\n",
            "123   FANG         0.741883\n",
            "50     BKR         0.730486\n",
            "299    OKE         0.653919\n",
            "409    WMB         0.651566\n",
            "252    MPC         0.633649\n",
            "\n",
            "Top 5 Price Correlation:\n",
            "    ticker  pearson_price\n",
            "136    ETN       0.949685\n",
            "20    AMZN       0.944881\n",
            "143    LLY       0.943307\n",
            "18    GOOG       0.939438\n",
            "17   GOOGL       0.938693\n",
            "\n",
            "Top 5 Returns Correlation:\n",
            "    ticker  pearson_returns\n",
            "188    HAL         0.696493\n",
            "50     BKR         0.677373\n",
            "347    SLB         0.670933\n",
            "251    MRO         0.605281\n",
            "123   FANG         0.593053\n",
            "\n",
            "Top 5 Non-linear Price:\n",
            "    ticker  spearman_price\n",
            "406   WELL        0.936595\n",
            "178     GE        0.936295\n",
            "136    ETN        0.934166\n",
            "247      L        0.933003\n",
            "176   GRMN        0.932218\n",
            "\n",
            "Top 5 Non-linear Returns:\n",
            "    ticker  spearman_returns\n",
            "188    HAL          0.673915\n",
            "50     BKR          0.642593\n",
            "347    SLB          0.642580\n",
            "251    MRO          0.607043\n",
            "123   FANG          0.600407\n",
            "\n",
            "Top 5 Beta Sensitivity:\n",
            "    ticker      beta\n",
            "50     BKR  0.913395\n",
            "85     CVX  0.896348\n",
            "159    XOM  0.859348\n",
            "235    KMI  0.858517\n",
            "409    WMB  0.829992\n",
            "\n",
            "Analysis complete. Results have been saved to CSV files and visualizations created.\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_tickers():\n",
        "    \"\"\"Load tickers from CSV file\"\"\"\n",
        "    try:\n",
        "        tickers_df = pd.read_csv('/content/tickers.csv')\n",
        "        return tickers_df.iloc[:, 0].tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading tickers: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def fetch_pair_data(base_ticker=\"FTI\", compare_ticker=None):\n",
        "    \"\"\"Fetch and prepare data for a pair of tickers\"\"\"\n",
        "    try:\n",
        "        end_date = datetime.now()\n",
        "        start_date = end_date - timedelta(days=2*365)\n",
        "\n",
        "        base = yf.Ticker(base_ticker)\n",
        "        base_data = base.history(start=start_date, end=end_date)\n",
        "\n",
        "        compare = yf.Ticker(compare_ticker)\n",
        "        compare_data = compare.history(start=start_date, end=end_date)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Base_Close': base_data['Close'],\n",
        "            'Compare_Close': compare_data['Close']\n",
        "        })\n",
        "\n",
        "        df = df.dropna()\n",
        "\n",
        "        df['Base_Returns'] = df['Base_Close'].pct_change()\n",
        "        df['Compare_Returns'] = df['Compare_Close'].pct_change()\n",
        "\n",
        "        df = df.replace([np.inf, -np.inf], np.nan)\n",
        "        df = df.dropna()\n",
        "\n",
        "        return df if len(df) > 30 else None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {compare_ticker}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def calculate_correlation_metrics(df):\n",
        "    \"\"\"Calculate various correlation metrics\"\"\"\n",
        "    try:\n",
        "        metrics = {\n",
        "            'pearson_price': df['Base_Close'].corr(df['Compare_Close']),\n",
        "            'pearson_returns': df['Base_Returns'].corr(df['Compare_Returns']),\n",
        "            'spearman_price': stats.spearmanr(df['Base_Close'], df['Compare_Close'])[0],\n",
        "            'spearman_returns': stats.spearmanr(df['Base_Returns'], df['Compare_Returns'])[0],\n",
        "            'beta': df['Base_Returns'].cov(df['Compare_Returns']) / df['Compare_Returns'].var(),\n",
        "            'data_points': len(df)\n",
        "        }\n",
        "        return metrics\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def analyze_all_correlations():\n",
        "    \"\"\"Analyze correlations for all tickers\"\"\"\n",
        "    # Load tickers\n",
        "    tickers = load_tickers()\n",
        "    print(f\"Loaded {len(tickers)} tickers for analysis\")\n",
        "\n",
        "    # Store results\n",
        "    results = []\n",
        "\n",
        "    # Define metric weights\n",
        "    weights = {\n",
        "        'pearson_price': 0.25,\n",
        "        'pearson_returns': 0.30,\n",
        "        'spearman_price': 0.15,\n",
        "        'spearman_returns': 0.20,\n",
        "        'beta': 0.10\n",
        "    }\n",
        "\n",
        "    # Define metric mapping for rankings\n",
        "    metric_mapping = {\n",
        "        'Price Correlation': 'pearson_price',\n",
        "        'Returns Correlation': 'pearson_returns',\n",
        "        'Non-linear Price': 'spearman_price',\n",
        "        'Non-linear Returns': 'spearman_returns',\n",
        "        'Beta Sensitivity': 'beta'\n",
        "    }\n",
        "\n",
        "    # Process each ticker\n",
        "    for ticker in tqdm(tickers, desc=\"Analyzing tickers\"):\n",
        "        df = fetch_pair_data(compare_ticker=ticker)\n",
        "\n",
        "        if df is not None:\n",
        "            metrics = calculate_correlation_metrics(df)\n",
        "\n",
        "            if metrics:\n",
        "                composite_score = sum(metrics[k] * weights[k] for k in weights.keys())\n",
        "\n",
        "                results.append({\n",
        "                    'ticker': ticker,\n",
        "                    **metrics,\n",
        "                    'composite_score': composite_score\n",
        "                })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Create rankings\n",
        "    rankings = {\n",
        "        'Composite Ranking': results_df.sort_values('composite_score', ascending=False),\n",
        "        'Price Correlation': results_df.sort_values('pearson_price', ascending=False),\n",
        "        'Returns Correlation': results_df.sort_values('pearson_returns', ascending=False),\n",
        "        'Non-linear Price': results_df.sort_values('spearman_price', ascending=False),\n",
        "        'Non-linear Returns': results_df.sort_values('spearman_returns', ascending=False),\n",
        "        'Beta Sensitivity': results_df.sort_values('beta', ascending=False)\n",
        "    }\n",
        "\n",
        "    # Save and print results\n",
        "    for name, ranking in rankings.items():\n",
        "        # Save top 20\n",
        "        filename = f\"ranking_{name.lower().replace(' ', '_')}.csv\"\n",
        "        ranking.head(20).to_csv(filename, index=False)\n",
        "\n",
        "        # Print top 5\n",
        "        print(f\"\\nTop 5 {name}:\")\n",
        "        if name == 'Composite Ranking':\n",
        "            display_cols = ['ticker', 'composite_score']\n",
        "        else:\n",
        "            metric_col = metric_mapping[name]\n",
        "            display_cols = ['ticker', metric_col]\n",
        "\n",
        "        print(ranking[display_cols].head())\n",
        "\n",
        "    return rankings\n",
        "\n",
        "def create_correlation_heatmap(rankings):\n",
        "    \"\"\"Create heatmap of top 20 correlated tickers\"\"\"\n",
        "    top_tickers = rankings['Composite Ranking']['ticker'].head(20).tolist()\n",
        "\n",
        "    # Fetch data for all top tickers\n",
        "    price_data = pd.DataFrame()\n",
        "    for ticker in top_tickers:\n",
        "        df = fetch_pair_data(compare_ticker=ticker)\n",
        "        if df is not None:\n",
        "            price_data[ticker] = df['Compare_Returns']\n",
        "\n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = price_data.corr()\n",
        "\n",
        "    # Create heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "    plt.title('Correlation Heatmap of Top 20 Related Tickers')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_heatmap.png')\n",
        "    plt.close()\n",
        "\n",
        "# Run the analysis\n",
        "print(\"Starting correlation analysis...\")\n",
        "rankings = analyze_all_correlations()\n",
        "create_correlation_heatmap(rankings)\n",
        "print(\"\\nAnalysis complete. Results have been saved to CSV files and visualizations created.\")"
      ]
    }
  ]
}
